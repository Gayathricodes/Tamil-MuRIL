{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Gayathricodes/Tamil-MuRIL/blob/main/TamilDataSet_MuRIL.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow_hub import KerasLayer"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "G2P0rrRjK8tR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KjrW4eMJmRW7",
        "outputId": "f6eb0485-13ac-4464-f03d-cab67444959e"
      },
      "source": [
        "!gpustat"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: line 1: gpustat: command not found\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RQEJ8IXkmTes",
        "outputId": "ed496226-2eb6-4131-cb04-418a5e3efcc1"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rmQuuzzJmG2g",
        "outputId": "2f8e1d18-a20d-4b16-8db4-ee28ee537184"
      },
      "source": [
        "!pip install gpustat"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gpustat\n",
            "  Downloading gpustat-1.1.1.tar.gz (98 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.1/98.1 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting nvidia-ml-py>=11.450.129 (from gpustat)\n",
            "  Downloading nvidia_ml_py-12.535.133-py3-none-any.whl (37 kB)\n",
            "Requirement already satisfied: psutil>=5.6.0 in /usr/local/lib/python3.10/dist-packages (from gpustat) (5.9.5)\n",
            "Collecting blessed>=1.17.1 (from gpustat)\n",
            "  Downloading blessed-1.20.0-py2.py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.4/58.4 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: wcwidth>=0.1.4 in /usr/local/lib/python3.10/dist-packages (from blessed>=1.17.1->gpustat) (0.2.13)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from blessed>=1.17.1->gpustat) (1.16.0)\n",
            "Building wheels for collected packages: gpustat\n",
            "  Building wheel for gpustat (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gpustat: filename=gpustat-1.1.1-py3-none-any.whl size=26535 sha256=a127fc28830e99cdea2446c1b7b5d0f7562896bec183151f361be105a6308558\n",
            "  Stored in directory: /root/.cache/pip/wheels/ec/d7/80/a71ba3540900e1f276bcae685efd8e590c810d2108b95f1e47\n",
            "Successfully built gpustat\n",
            "Installing collected packages: nvidia-ml-py, blessed, gpustat\n",
            "Successfully installed blessed-1.20.0 gpustat-1.1.1 nvidia-ml-py-12.535.133\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hifvghb-mfeg",
        "outputId": "6b8066b2-6bed-4515-c2c0-65c9c5791d99"
      },
      "source": [
        "!pwd\n",
        "import os\n",
        "os.chdir('/content/drive/My Drive/MuRIL')\n",
        "!pwd"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "/content/drive/My Drive/MuRIL\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LjNwvRhbmfin",
        "outputId": "2bd157fa-021f-498a-d418-195117e75bba"
      },
      "source": [
        "!pip install bert-for-tf2\n",
        "!pip install sentencepiece"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting bert-for-tf2\n",
            "  Downloading bert-for-tf2-0.14.9.tar.gz (41 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.2/41.2 kB\u001b[0m \u001b[31m685.5 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting py-params>=0.9.6 (from bert-for-tf2)\n",
            "  Downloading py-params-0.10.2.tar.gz (7.4 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting params-flow>=0.8.0 (from bert-for-tf2)\n",
            "  Downloading params-flow-0.8.2.tar.gz (22 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from params-flow>=0.8.0->bert-for-tf2) (1.23.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from params-flow>=0.8.0->bert-for-tf2) (4.66.1)\n",
            "Building wheels for collected packages: bert-for-tf2, params-flow, py-params\n",
            "  Building wheel for bert-for-tf2 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for bert-for-tf2: filename=bert_for_tf2-0.14.9-py3-none-any.whl size=30509 sha256=e298edecc4120eca804f9306366b17c30dd98d911f3959c96c6b754e5c301ba4\n",
            "  Stored in directory: /root/.cache/pip/wheels/d8/da/50/126d7b8416d9a0e6bf876935c2219a71e72a6529c25e150c56\n",
            "  Building wheel for params-flow (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for params-flow: filename=params_flow-0.8.2-py3-none-any.whl size=19454 sha256=69e60282ff3321cc8e720d11d6fed4ac7bf06a8f56f4a9545d58477b0837eb00\n",
            "  Stored in directory: /root/.cache/pip/wheels/97/a8/d0/f7419404174976a2686bb98b5c30df01cc71445415f32db9e6\n",
            "  Building wheel for py-params (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for py-params: filename=py_params-0.10.2-py3-none-any.whl size=7891 sha256=4dec38ff48b6f856d21050181d1ef67416596e633d7cedb1f832a862edc37d8f\n",
            "  Stored in directory: /root/.cache/pip/wheels/69/c8/b3/92666cff9fb312bc3473eaa6b396695b89a7b3e31e90876819\n",
            "Successfully built bert-for-tf2 params-flow py-params\n",
            "Installing collected packages: py-params, params-flow, bert-for-tf2\n",
            "Successfully installed bert-for-tf2-0.14.9 params-flow-0.8.2 py-params-0.10.2\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (0.1.99)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cwJ7igw4mfgt",
        "outputId": "ceb78e85-cf7c-4dbb-a72e-1999d49fecc3"
      },
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import bert\n",
        "from tensorflow.keras.models import  Model\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from collections import namedtuple\n",
        "from sklearn import preprocessing\n",
        "from bert import bert_tokenization\n",
        "print(\"TensorFlow Version:\",tf.__version__)\n",
        "print(\"Hub version: \",hub.__version__)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TensorFlow Version: 2.15.0\n",
            "Hub version:  0.16.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1QixDBKKoESF"
      },
      "source": [
        "# Load train and val datasets\n",
        "df_train = pd.read_csv('tamilds_train_80.tsv', sep = \"\\t\")\n",
        "df_val = pd.read_csv('tamilds_val_20.tsv', sep = \"\\t\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YEXVtLY4zKXA",
        "outputId": "31cd34dd-eb37-47d0-adf7-75e30618d560"
      },
      "source": [
        "# Columns\n",
        "df_train.columns"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['Message', 'Type'], dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BW-PO8F8p4HA",
        "outputId": "163848c1-6286-4217-fd3c-420d2fe8ef1c"
      },
      "source": [
        "# Prepare input text and one hot encoded labels for train and validation sets\n",
        "\n",
        "unique_labels = list(np.unique(df_train[\"Type\"]))\n",
        "\n",
        "train_x = df_train[\"Message\"].values\n",
        "train_y = df_train[\"Type\"].values\n",
        "\n",
        "le = preprocessing.LabelEncoder()\n",
        "\n",
        "train_y = le.fit_transform(train_y)\n",
        "train_y = tf.keras.utils.to_categorical(train_y, num_classes=len(unique_labels), dtype='float32')\n",
        "\n",
        "val_x = df_val[\"Message\"].values\n",
        "val_y = df_val[\"Type\"].values\n",
        "\n",
        "val_y = le.fit_transform(val_y)\n",
        "val_y = tf.keras.utils.to_categorical(val_y, num_classes=len(unique_labels), dtype='float32')\n",
        "\n",
        "\n",
        "print(\"number of unique labels\", len(unique_labels))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "number of unique labels 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nUD20x5Oqzgp",
        "outputId": "cb0129e9-0be0-4ad6-b7f7-eb154aa8f72a"
      },
      "source": [
        "# Check unique labels\n",
        "unique_labels"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Ham', 'Spam']"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nEHX4WgmnIkM"
      },
      "source": [
        "# Function to create input_ids\n",
        "def get_ids(tokens, tokenizer, max_seq_length):\n",
        "    \"\"\"Token ids from Tokenizer vocab\"\"\"\n",
        "    token_ids = tokenizer.convert_tokens_to_ids(tokens,)\n",
        "    input_ids = token_ids + [0] * (max_seq_length-len(token_ids))\n",
        "    return input_ids\n",
        "\n",
        "# Function to create attention masks\n",
        "def get_masks(tokens, max_seq_length):\n",
        "    return [1]*len(tokens) + [0] * (max_seq_length - len(tokens))\n",
        "\n",
        "# Function to create segment ids\n",
        "def get_segments(tokens, max_seq_length):\n",
        "    \"\"\"Segments: 0 for the first sequence, 1 for the second\"\"\"\n",
        "    segments = []\n",
        "    current_segment_id = 0\n",
        "    for token in tokens:\n",
        "        segments.append(current_segment_id)\n",
        "        if token == \"[SEP]\":\n",
        "            current_segment_id = 1\n",
        "    return segments + [0] * (max_seq_length - len(tokens))\n",
        "\n",
        "# Function to create input_ids, attention_masks, segment_ids for sample\n",
        "def create_single_input(sentence,MAX_LEN, MAX_SEQ_LEN):\n",
        "\n",
        "  stokens = tokenizer.tokenize(sentence)\n",
        "\n",
        "  stokens = stokens[:MAX_LEN]\n",
        "\n",
        "  stokens = [\"[CLS]\"] + stokens + [\"[SEP]\"]\n",
        "\n",
        "  ids = get_ids(stokens, tokenizer, MAX_SEQ_LEN)\n",
        "  masks = get_masks(stokens, MAX_SEQ_LEN)\n",
        "  segments = get_segments(stokens, MAX_SEQ_LEN)\n",
        "\n",
        "  return ids,masks,segments\n",
        "\n",
        "def create_input_array(sentences, MAX_SEQ_LEN):\n",
        "\n",
        "  input_ids, input_masks, input_segments = [], [], []\n",
        "\n",
        "  for sentence in tqdm(sentences,position=0, leave=True):\n",
        "\n",
        "    ids,masks,segments=create_single_input(sentence,MAX_SEQ_LEN-2, MAX_SEQ_LEN)\n",
        "\n",
        "    input_ids.append(ids)\n",
        "    input_masks.append(masks)\n",
        "    input_segments.append(segments)\n",
        "\n",
        "  return [np.asarray(input_ids, dtype=np.int32),\n",
        "            np.asarray(input_masks, dtype=np.int32),\n",
        "            np.asarray(input_segments, dtype=np.int32)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q8AmiWuknTKL"
      },
      "source": [
        "# MuRIL model layer\n",
        "muril_layer = hub.KerasLayer(\"https://tfhub.dev/google/MuRIL/1\", trainable=True)\n",
        "\n",
        "# Create tokenizer\n",
        "vocab_file = muril_layer.resolved_object.vocab_file.asset_path.numpy()\n",
        "do_lower_case = muril_layer.resolved_object.do_lower_case.numpy()\n",
        "tokenizer = bert_tokenization.FullTokenizer(vocab_file, do_lower_case)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZDqjXUqturNk",
        "outputId": "23c867b0-2b4a-442b-be3b-71df697c7a74"
      },
      "source": [
        "# Create input_ids, attention_masks, segment_ids for training and validation sets with max_seq_len as 128\n",
        "max_seq_len = 128\n",
        "train_x = create_input_array(train_x, max_seq_len)\n",
        "val_x = create_input_array(val_x, max_seq_len)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 940/940 [00:00<00:00, 3923.60it/s]\n",
            "100%|██████████| 235/235 [00:00<00:00, 2828.75it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DtImk-2eqn4a"
      },
      "source": [
        "# Define model function - compile and fit\n",
        "def model_fit(train_x, train_y, val_x, val_y, max_seq_length, num_epochs, muril_layer):\n",
        "\n",
        "  input_word_ids = tf.keras.layers.Input(shape=(max_seq_length,), dtype=tf.int32,\n",
        "                                       name=\"input_word_ids\")\n",
        "  input_mask = tf.keras.layers.Input(shape=(max_seq_length,), dtype=tf.int32,\n",
        "                                   name=\"input_mask\")\n",
        "  segment_ids = tf.keras.layers.Input(shape=(max_seq_length,), dtype=tf.int32,\n",
        "                                    name=\"segment_ids\")\n",
        "\n",
        "  outputs = muril_layer(dict(input_word_ids = input_word_ids, input_mask = input_mask, input_type_ids = segment_ids))\n",
        "\n",
        "  x = tf.keras.layers.Dropout(0.2)(outputs[\"pooled_output\"]) # take pooled output layer\n",
        "  final_output = tf.keras.layers.Dense(2, activation=\"softmax\")(x)\n",
        "\n",
        "  model = tf.keras.models.Model(\n",
        "      inputs=[input_word_ids, input_mask, segment_ids], outputs=final_output)\n",
        "\n",
        "  model.compile(loss='binary_crossentropy',\n",
        "                  optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n",
        "                  metrics=['accuracy'])\n",
        "  model.fit(train_x, train_y, epochs = num_epochs, batch_size = 16, validation_data = (val_x, val_y), shuffle = False)\n",
        "\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dfQ_Jv6sulcq",
        "outputId": "dd6516e0-2e6a-4ac7-c4e6-c15d82c674a2"
      },
      "source": [
        "# Set number of epochs\n",
        "num_epochs = 10\n",
        "\n",
        "# Get the model object\n",
        "model = model_fit(train_x, train_y, val_x, val_y, max_seq_len, num_epochs, muril_layer)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "59/59 [==============================] - 58s 487ms/step - loss: 0.4121 - accuracy: 0.9011 - val_loss: 1.3265 - val_accuracy: 0.4298\n",
            "Epoch 2/10\n",
            "59/59 [==============================] - 27s 464ms/step - loss: 0.2966 - accuracy: 0.9170 - val_loss: 1.5752 - val_accuracy: 0.4298\n",
            "Epoch 3/10\n",
            "59/59 [==============================] - 28s 479ms/step - loss: 0.2993 - accuracy: 0.9170 - val_loss: 1.5927 - val_accuracy: 0.4298\n",
            "Epoch 4/10\n",
            "59/59 [==============================] - 28s 471ms/step - loss: 0.2989 - accuracy: 0.9170 - val_loss: 1.5930 - val_accuracy: 0.4298\n",
            "Epoch 5/10\n",
            "59/59 [==============================] - 28s 480ms/step - loss: 0.2978 - accuracy: 0.9170 - val_loss: 1.5666 - val_accuracy: 0.4298\n",
            "Epoch 6/10\n",
            "59/59 [==============================] - 28s 480ms/step - loss: 0.2955 - accuracy: 0.9170 - val_loss: 1.5633 - val_accuracy: 0.4298\n",
            "Epoch 7/10\n",
            "59/59 [==============================] - 28s 471ms/step - loss: 0.2950 - accuracy: 0.9170 - val_loss: 1.5644 - val_accuracy: 0.4298\n",
            "Epoch 8/10\n",
            "59/59 [==============================] - 28s 481ms/step - loss: 0.2944 - accuracy: 0.9170 - val_loss: 1.5663 - val_accuracy: 0.4298\n",
            "Epoch 9/10\n",
            "59/59 [==============================] - 28s 470ms/step - loss: 0.2947 - accuracy: 0.9170 - val_loss: 1.5648 - val_accuracy: 0.4298\n",
            "Epoch 10/10\n",
            "59/59 [==============================] - 28s 470ms/step - loss: 0.2958 - accuracy: 0.9170 - val_loss: 1.5621 - val_accuracy: 0.4298\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "score = model.evaluate(val_x, val_y, verbose = 0)\n",
        "\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "metadata": {
        "id": "4R-mO7YBjXq5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, roc_curve\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "accuracy = accuracy_score(val_x, val_y)\n",
        "\n",
        "# Precision\n",
        "precision = precision_score(val_x, val_y)\n",
        "\n",
        "# Recall\n",
        "recall = recall_score(val_x, val_y)\n",
        "\n",
        "# F1-score\n",
        "f1 = f1_score(val_x, val_y)\n",
        "\n",
        "# AUC-ROC\n",
        "auc_roc = roc_auc_score(val_x, val_y)\n",
        "\n",
        "# ROC Curve\n",
        "fpr, tpr, thresholds = roc_curve(val_x, val_y)\n",
        "\n",
        "# Plot ROC curve\n",
        "plt.plot(fpr, tpr, label='ROC curve (area = %0.2f)' % auc_roc)\n",
        "plt.plot([0, 1], [0, 1], 'k--')  # Random guess curve\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
        "plt.legend(loc='lower right')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "j7iaU3r4hDWo"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}